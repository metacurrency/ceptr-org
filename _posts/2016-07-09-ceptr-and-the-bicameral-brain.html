---
layout: post
status: publish
published: true
title: Ceptr and the Bicameral Brain
author: Eric Harris-Braun
author_login: Eric Harris-Braun
author_email: eric@harris-braun.com
author_url: http://eric.harris-braun.com
wordpress_id: 155
wordpress_url: http://ceptr.org/?p=155
date: '2016-07-09 05:43:38 -0400'
date_gmt: '2016-07-09 01:43:38 -0400'
categories: []
tags:
- dev
comments: []
redirect_from: "/2016/07/09/ceptr-and-the-bicameral-brain/"
---
<div class="dev-callout">This is #4 in a series of <a href="/blog?tag=dev">dev posts</a>.</div><br />
This past month I've made little coding progress. I'm still sorting through some Semtrex bugs in the few time windows I've had. So this month I want to share a higher level pattern and perhaps a bit more philosophical view on Ceptr coding.</p>
<p>As we've been developing Ceptr, we've recognized two different approaches to solving programming problems. The first is what we might call the linear or algorithmic approach, and the second we might think of as a simultaneous or pattern matching approach.
</p>

<p>Most coders are very familiar with the first approach because most programs are built that way--constructing a sequence of instructions to solve a given problem.  However, you might also be familiar with the pattern matching approach if you've coded in a 4th gen language like Prolog or Mathematica. In this scenario, a program is built out of a set of expectations that match against incoming signals or data which trigger actions that send more signals which trigger other actions and so on.  </p>
<p>If you've coded in any event driven environment, (which you have if you do pretty much any web coding in JavaScript) you are actually relying on the pattern matching approach. It's just more hidden from view because the pattern matching gets translated to an event to which your code is attached as a handler.  So you can just attach your actions to events like onClick, onMouseOver, etc.</p>
<p>Ceptr embodies both these approaches in an interesting dialectic.  Pattern matching happens in Ceptr at two very distinct loci: in the <b>membranes</b>, and in the <b>scapes</b>.  <br />
</p>
<p><b>Membrane pattern matching: </b></p>
<p>Every receptor is bounded by a membrane which receives external signals (as well as signals from internal receptors -- see <a href="http://ceptr.org/2016/04/27/musings-on-coding-in-ceptr-signaling/">this post</a> for more details on Ceptr signaling). When incoming signals match on a pattern, the associated action gets triggered. The action is a more traditional algorithmic "program" in the form of a run-tree, a tree of instructions that get reduced to its result by the Ceptr virtual machine.  These algorithmic run-trees can trigger other actions: send signals to other receptors, send signals back to the same receptor for further pattern matching, or actually change the receptor's internal state.</p>
<p><b>Scape pattern matching: </b></p>
<p>Every receptor holds state data in a kind of atomic object store, and we use scapes to organize that collections and relationships between the units of data.  We chose this word to evoke a textured, geometric sense, of holding data in a relational fabric -- a kind of data landscape. You can attach listeners to scapes which trigger actions linked to patterns as data gets added, changed or removed.  So, for example, an update to someone's location could trigger a notification that your friend is nearby.</p>
<p>Thus, programs in Ceptr are built out of both left brain (linear) and right brain (gestalt/pattern matching) components. So coding will consist of thinking both algorithmically, i.e. in a procedural, sequential programming steps way: the actions to be triggered, as well as in a parallel in a more holistic pattern matching sort of way: the expectations to be matching, both in terms of arriving signals, and changing state.  Our sense is that as we get deeper into the implementation of Ceptr, we'll be able to push the semtrex pattern matching off to parallelized architectures (i.e. GPU's) that can very efficiently scan incoming signals and changes on scapes, leaving the more sequential tree-reduction processing to the traditional CPU.</p>
<p>Here comes the more philosophical/fanciful stuff.  It's the result of connecting ideas from two different books to the coding approaches described above.  I've recently finished <a href="https://www.goodreads.com/book/show/3119173-skin-of-culture">The Skin of Culture</a> by Derrick de Kerckhove, in which he presents some absolutely fascinating conclusions about the relationship between writing systems and human left and right brain hemispheres propensity to specialize, one in linear/sequential and the other in holistics/gestalt processing.  His research reveals that almost without exception all alphabetic writing systems in which the vowels are implicit as well as all ideographic writing systems, are read right to left.  Whereas alphabetic writing systems that include the vowels scan left to right, and furthermore, systems that switched from having implicit vowels to then adding them explicitly, then switched their scan direction.</p>
<p><img class="image right" src="/images/visual_pathways.jpg" alt="VisualPathways" width="500" height="486" />De Kerckhove claims that this is directly due to processing-type efficiency differences in the hemispheres because of the way the left and right portions of our visual field map to them (see diagram).  In his own words:</p>
<blockquote><p>To read any writing system, you have to recognize the shape of the symbols and analyze the sequence of symbols.  Depending upon which is the more urgent, shape or sequence, the writing system will go left or right.  If you have to guess and cross-check the writing, it is important to see the shape first.  Arabic and Hebraic readers cross-check their texts, for example, because they have to guess the unwritten vowels.  For the instant survey of an entire field, our left field of vision works faster and better than the right.  On the other hand, when we read Dutch or English, we first have to see the order of the letters one after the other, a task better accomplished by the right visual field.  That is why our alphabet, a linear, sequential system of coded information, is written to the right.  This is my primary hypothesis.</blockquote><br />
The second book is one that I read back in college for a philosophy course: <a href="https://en.wikipedia.org/wiki/Bicameralism_(psychology)">The Origin of Consciousness and the Breakdown of the Bicameral Mind</a> by Julian Jaynes.  This book presents the radical hypothesis that what we understand as "consciousness" i.e. that self-conscious introspective awareness of our own awareness, is a very new phenomenon, appearing as recently as only 5000-3000 years ago, and comes from some kind unification of the capacities of the two brain hemispheres.</p>
<p>Well, what happened between five and three thousand years ago? The arrival of those new that new expressive capacities of writing &amp; money!  I've written a bit about "new expressive capacities" for example: <a href="http://eric.harris-braun.com/blog/2010/09/08/id-170">here</a> and <a href="http://archive.metacurrency.org/blog/2010/10/22/composable-abstractions-for-wealth-building">here</a>, because I think they always provide the core element necessary for fundamental systems change.  But connecting the dots with processing modalities, i.e. those two different approaches to coding that are interwoven in Ceptr in what I think is a new way, well, that's cool!</p>
<p>Of course my hope, and design, is that Ceptr lives up to being a new expressive capacity that provides a good match with truths about underlying systemics, and even the underlying neural structures of those who use it, such that new levels of consciousness become possible both individually and collectively.</p>
